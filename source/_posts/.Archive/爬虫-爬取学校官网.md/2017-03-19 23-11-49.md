---
title: 爬虫-爬取学校官网
categories: python-crawler
---

# 前言
> 之前断断续续的学习爬虫，结果忘得差不多了，现在重新开始认真学，公众号也要认真弄了，之前做了就一直没管  哈哈  就图个装逼！！

# 结构分析
![](爬虫-爬取学校官网/1.png)
> 正常的登录界面，可以写出以下代码:

## 初始化
``` py
# 传入对应用户名(studentnumber),密码(password),学校官网(schoolURL)
def __init__(self,studentnumber,password,schoolURL):
        self.studentnumber = studentnumber
        self.password = password
        self.schoolURL = schoolURL
        resp = requests.get(schoolURL)
        self.sl = etree.HTML(resp.content)
```
> 接下来就是验证码了，由于并没有找到好的库来识别验证码，就采用人工输入好了，就像超级课程表那样

## 验证码
``` py
#拿到图片
    def getCheckCode(self):
        imgURL = self.schoolURL+'/CheckCode.aspx'
        imgResp = requests.get(imgURL, stream=True)
        image = imgResp.content
        try:
            with open('code.jpg','wb') as f:
                f.write(image)
        except IOError,e:
            print("IO Error:%s" % e)
        finally:
            f.close()
```
> 拿到图片，并下载到本地

## 数据准备
![](爬虫-爬取学校官网/2.png)
> 由图可知所需发送的数据:

``` py
def getData(self,checkCode):
        VIEWSTATE = self.sl.xpath('//input[@name="__VIEWSTATE"]/@value')[0]
        VIEWSTATEGENERATOR = self.sl.xpath('//input[@name="__VIEWSTATEGENERATOR"]/@value')[0]
        data = {
            '__VIEWSTATE': VIEWSTATE,
            '__VIEWSTATEGENERATOR': VIEWSTATEGENERATOR,
            'txtUserName': self.studentnumber,
            'Textbox1': '',
            'Textbox2': self.password,
            'txtSecretCode': checkCode,
            'RadioButtonList1':u'学生'.encode('gb2312'),
            'Button1':'',
            'lbLanguage':'',
            'hidPdrs':'',
            'hidsc':''
            }
        return data
```

## 登录
> 登录并拿到登陆者的姓名

![](爬虫-爬取学校官网/3.png)
``` py
def login(self,checkCode):    
        headers = {
            "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.110 Safari/537.36",
        }
        data = self.getData(checkCode)
        #登陆教务系统
        response = requests.post(self.schoolURL,data=data,headers=headers)
        successSl = etree.HTML((response.content).decode('gb2312'))
#         print response.encoding
#       去除登陆者姓名同学两字(xxx同学)
        self.name = successSl.xpath('//span[@id="xhxm"]/text()')[0][:-2]
```
> 登录，并拿到登录者姓名

## 进入课表页面
![](爬虫-爬取学校官网/4.png)
> 可知queryString为tjkbcx.aspx?xh=2014115010127&xm=黄辉辉&gnmkdm=N121601，代码如下:

``` py
def getCourse(self):
        #tjkbcx.aspx?xh=2014115010127&xm=黄辉辉&gnmkdm=N121601
        courseString = {
            'xh':self.studentnumber,
            'xm':self.name,
            'gnmkdm':'N121601'
        }
        baseURL = "tjkbcx.aspx?%s" % urllib.urlencode(courseString)
        courseURL = self.schoolURL+baseURL
#         print courseURL
        #必须要有Referer这个参数，否者跳到登录页面
        headers = {
        "Referer":"http://www.jwgl.hbnu.edu.cn/(qsyyr145roe1hwvyfoylp445)/default2.aspx",
        "User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36",
         }
        contents =  resp.content.decode('gb2312')
        sl = etree.HTML(contents)
        for course in sl.xpath('//td/text()'):
            print course
```
> 由于表格样式不好调试，可以通过截屏拿到课表

``` py
driver = webdriver.PhantomJS()
driver.get(courseURL)
driver.save_screenshot("course.jpg")
```
> 由于缺少请求头，上网查后发现:

``` py
dcap = dict(DesiredCapabilities.PHANTOMJS)
dcap["phantomjs.page.settings.userAgent"] = (
         "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"
  )
driver = webdriver.PhantomJS(desired_capabilities=dcap)
```
> 由于请求头还缺少`referer`